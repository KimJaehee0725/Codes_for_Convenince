{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train_and_Eval.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSoy60kFc4dX"
      },
      "source": [
        "import torch\n",
        "import copy\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\"\"\"\n",
        "모델과 데이터를 입력받아 훈련하고, 평가하며, 훈련된 모델과 예측값을 저장하는 함수\n",
        "\n",
        "\n",
        "train 데이터 loader와 val 데이터 로더를 입력값으로 한다. \n",
        "모델은 gpu에 싣지 않은 상태로 입력되도 gpu에 알아서 실린다. \n",
        "scheduler의 경우 사용하지 않아도 상관없다. \n",
        "기본적인 손실 함수는 cross entropy다.\n",
        "\n",
        "early_stopping은 tolerance를 설정하여 accuracy 기준으로 early_stopping한다. \n",
        "make_pred는 예측값을 만들어서 working directory에 저장해준다. \n",
        "save_mode 역시 early stopping된 모델을 working directory에 저장해준다. \n",
        "\n",
        "향후 클래스 분리 예정. 현재 코드는 좋지 못한 형태이다. \n",
        "\"\"\"\n",
        "class train_the_model():\n",
        "  def __init__(self, train_data_loader, val_data_loader, device, epochs, model, optimizer, batch_size, scheduler = None, loss_function = F.cross_entropy):\n",
        "    self.train_data_loader = train_data_loader\n",
        "    self.val_data_loader = val_data_loader  \n",
        "    self.device = device\n",
        "    self.epochs = epochs\n",
        "    self.model = model.to(self.device)\n",
        "    self.optimizer = optimizer\n",
        "    self.batch_size = batch_size\n",
        "    self.model_es = copy.deepcopy(model)\n",
        "    self.scheduler = scheduler\n",
        "    self.loss_function = loss_function\n",
        "\n",
        "  def _train(self):\n",
        "    self.model.train()\n",
        "    \n",
        "    for batch_idx, (_feature, _label) in enumerate(self.train_data_loader):\n",
        "      _feature, _label = _feature.to(self.device), _label.to(self.device)\n",
        "      self.optimizer.zero_grad()\n",
        "      output = self.model(_feature)\n",
        "      loss = self.loss_function(output, _label)\n",
        "      loss.backward()\n",
        "      self.optimizer.step()\n",
        "\n",
        "      if self.scheduler:\n",
        "        self.scheduler.step()\n",
        "\n",
        "  def evaluate(self):\n",
        "    self.model.eval()\n",
        "    train_loss = 0\n",
        "    val_loss = 0\n",
        "    train_correct = 0\n",
        "    val_correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for val_feat, val_lab in self.val_data_loader:\n",
        "        val_feat, val_lab = val_feat.to(self.device), val_lab.to(self.device)\n",
        "        val_output = self.model(val_feat)\n",
        "\n",
        "        val_loss += F.cross_entropy(val_output, val_lab, reduction = \"sum\").item()\n",
        "        val_pred = val_output.max(1, keepdim = True)[1]\n",
        "        val_correct += val_pred.eq(val_lab.view_as(val_pred)).sum().item()\n",
        "\n",
        "      for train_feat, train_lab in self.train_data_loader:\n",
        "        train_feat, train_lab = train_feat.to(self.device), train_lab.to(self.device)\n",
        "        train_output = self.model(train_feat)\n",
        "\n",
        "        train_loss += F.cross_entropy(train_output, train_lab, reduction = \"sum\").item()\n",
        "        train_pred = train_output.max(1, keepdim = True)[1]\n",
        "        train_correct += train_pred.eq(train_lab.view_as(train_pred)).sum().item()\n",
        "\n",
        "    train_loss /= len(self.train_data_loader.dataset)\n",
        "    val_loss /= len(self.val_data_loader.dataset)\n",
        "\n",
        "    train_acc = 100 * train_correct / len(self.train_data_loader.dataset)\n",
        "    val_acc = 100 * val_correct / len(self.val_data_loader.dataset)\n",
        "\n",
        "    return train_loss, train_acc, val_loss, val_acc\n",
        "\n",
        "  def early_stop(self, val_loss_es, val_acc_es, model, tolerance):\n",
        "    if self.min_acc == 'start':\n",
        "      self.count = 0\n",
        "      self.min_loss = val_loss_es\n",
        "      self.min_acc = val_acc_es\n",
        "    if self.min_acc < val_acc_es:\n",
        "      self.count = 0\n",
        "      self.min_loss = val_loss_es\n",
        "      self.min_acc = val_acc_es\n",
        "      self.model_es = copy.deepcopy(self.model)\n",
        "    else :\n",
        "      self.count += 1\n",
        "      if self.count == tolerance:\n",
        "        print(\"================================================================================================================================\")\n",
        "        print(\"================================================================================================================================\")\n",
        "        print(\"====================================================Learing the Data is Over====================================================\")\n",
        "        print(f\"============================final accuracy : {self.min_acc} =========== final loss : {self.min_loss}============================\")\n",
        "        return \"break\"        \n",
        "\n",
        "  def train_val_epoch(self, tolerance):\n",
        "    self.min_acc = 'start'\n",
        "    self.val_loss_list = []\n",
        "    self.val_acc_list = []\n",
        "    self.train_loss_list = []\n",
        "    self.train_acc_list = []\n",
        "\n",
        "    self.epoch_num = 0\n",
        "    for epoch in range(1, self.epochs):\n",
        "      start = time.time()\n",
        "      self.epoch_num += 1\n",
        "      self._train()\n",
        "      train_l, train_ac, val_l, val_ac = self.evaluate()\n",
        "\n",
        "      self.val_loss_list.append(val_l)\n",
        "      self.val_acc_list.append(val_ac)\n",
        "      self.train_loss_list.append(train_l)\n",
        "      self.train_acc_list.append(train_ac)\n",
        "\n",
        "      state_of_early_stop = self.early_stop(val_l, val_ac, self.model, tolerance)\n",
        "      end = time.time()\n",
        "      if state_of_early_stop == \"break\": break\n",
        "      print(f\"===================================================={self.epoch_num} epoch 완료====================================================\")\n",
        "      print(f\"TRAIN loss : {round(train_l, 4)} accuracy : {round(train_ac, 4)}\")\n",
        "      print(f\"VALID loss : {round(val_l, 4)} accuracy : {round(val_ac, 4)}\") \n",
        "      print(f\"duration: {round(end - start, 1)}\")\n",
        "\n",
        "    self.epochs_list = range(1,(self.epoch_num + 1))\n",
        "    \n",
        "    plt.figure(figsize = (12, 3))\n",
        "    plt.subplot(2, 1, 1)\n",
        "    \n",
        "    plt.plot(self.epochs_list, self.train_acc_list, 'b', label='train accuracy')\n",
        "    plt.plot(self.epochs_list, self.val_acc_list, 'g', label='val accuracy')\n",
        "    plt.title('Train, Validation accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.plot(self.epochs_list, self.train_loss_list, 'b', label='train loss')\n",
        "    plt.plot(self.epochs_list, self.val_loss_list, 'g', label='val loss')\n",
        "    plt.title('Train, Validation loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "  def save_model(self, model_name):\n",
        "    torch.save(self.model_es, f'./model_save/{model_name}.pt')\n",
        "\n",
        "\n",
        "  def make_pred(self, test_data_x, test_data_label, file_name):\n",
        "    self.model_es.eval()\n",
        "    self.test_x = test_data_x.to(self.device)\n",
        "    self.test_label = test_data_label\n",
        "    self.pred = self.model_es(self.test_x)\n",
        "    self.pred_y = self.pred.max(1, keepdim = True)[1].cpu().numpy()\n",
        "\n",
        "    self.tmp = [a[0] for a in self.pred_y]\n",
        "    self.tmp2 = list(self.test_label)\n",
        "\n",
        "    self.trial_df = pd.DataFrame({'ID' : self.tmp2, \"Category\" :self.tmp})\n",
        "    self.path = os.getcwd() + '/trial'\n",
        "    self.trial_df.to_csv(self.path + file_name, index = False)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}